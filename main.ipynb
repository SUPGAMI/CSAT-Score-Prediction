{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3a0dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.30      0.38      2246\n",
      "           2       0.05      0.01      0.02       256\n",
      "           3       0.05      0.01      0.02       512\n",
      "           4       0.16      0.05      0.07      2244\n",
      "           5       0.73      0.92      0.81     11924\n",
      "\n",
      "    accuracy                           0.68     17182\n",
      "   macro avg       0.30      0.26      0.26     17182\n",
      "weighted avg       0.60      0.68      0.62     17182\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  685     8    11    72  1470]\n",
      " [   32     3     4     9   208]\n",
      " [   59     5     7    21   420]\n",
      " [  119    10    25   102  1988]\n",
      " [  443    31    81   433 10936]]\n",
      "\n",
      "Predicted CSAT Score for new data: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Set seaborn style for better visuals\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Customer_support_data.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert date-time columns to datetime\n",
    "df['Issue_reported at'] = pd.to_datetime(df['Issue_reported at'], format='%d-%m-%Y %H:%M')\n",
    "df['issue_responded'] = pd.to_datetime(df['issue_responded'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "# Calculate response time in minutes\n",
    "df['response_time_minutes'] = (df['issue_responded'] - df['Issue_reported at']).dt.total_seconds() / 60\n",
    "\n",
    "# Handle missing values\n",
    "df['Customer Remarks'] = df['Customer Remarks'].fillna('No comment')\n",
    "\n",
    "# Drop irrelevant or high-cardinality columns\n",
    "columns_to_drop = ['Unique id', 'Order_id', 'order_date_time', 'Survey_response_Date',\n",
    "                   'Customer_City', 'Product_category', 'Item_price', 'connected_handling_time',\n",
    "                   'Supervisor', 'Manager']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Clean text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Customer Remarks'] = df['Customer Remarks'].apply(clean_text)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='CSAT Score', data=df)\n",
    "plt.title('Class Distribution of CSAT Scores')\n",
    "plt.xlabel('CSAT Score')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['CSAT Score'])\n",
    "y = df['CSAT Score']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define preprocessing steps\n",
    "categorical_cols = ['channel_name', 'category', 'Sub-category', 'Agent_name', 'Tenure Bucket', 'Agent Shift']\n",
    "numerical_cols = ['response_time_minutes']\n",
    "text_col = 'Customer Remarks'\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_cols),\n",
    "        ('text', TfidfVectorizer(max_features=500, stop_words='english'), text_col)\n",
    "    ])\n",
    "\n",
    "# Create model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix heatmap\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted CSAT Score')\n",
    "plt.ylabel('True CSAT Score')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot classification report metrics\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [report[str(i)]['precision'] for i in range(1, 6)],\n",
    "    'Recall': [report[str(i)]['recall'] for i in range(1, 6)],\n",
    "    'F1-Score': [report[str(i)]['f1-score'] for i in range(1, 6)]\n",
    "}, index=[1, 2, 3, 4, 5])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics_df.plot(kind='bar')\n",
    "plt.title('Classification Metrics by CSAT Score')\n",
    "plt.xlabel('CSAT Score')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(title='Metric')\n",
    "plt.savefig('classification_metrics.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importances = model.named_steps['classifier'].feature_importances_\n",
    "feature_names = (\n",
    "    numerical_cols +\n",
    "    model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_cols).tolist() +\n",
    "    model.named_steps['preprocessor'].named_transformers_['text'].get_feature_names_out().tolist()\n",
    ")\n",
    "\n",
    "# Create DataFrame and select top 10 features\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'csat_prediction_model.pkl')\n",
    "\n",
    "# Example: Predict on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'channel_name': ['Inbound'],\n",
    "    'category': ['Returns'],\n",
    "    'Sub-category': ['Reverse Pickup Enquiry'],\n",
    "    'Customer Remarks': ['Good service, quick response'],\n",
    "    'Agent_name': ['John Smith'],\n",
    "    'Tenure Bucket': ['>90'],\n",
    "    'Agent Shift': ['Morning'],\n",
    "    'Issue_reported at': ['2023-08-01 10:00'],\n",
    "    'issue_responded': ['2023-08-01 10:15']\n",
    "})\n",
    "\n",
    "# Preprocess new data\n",
    "new_data['Issue_reported at'] = pd.to_datetime(new_data['Issue_reported at'])\n",
    "new_data['issue_responded'] = pd.to_datetime(new_data['issue_responded'])\n",
    "new_data['response_time_minutes'] = (new_data['issue_responded'] - new_data['Issue_reported at']).dt.total_seconds() / 60\n",
    "new_data['Customer Remarks'] = new_data['Customer Remarks'].apply(clean_text)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(new_data)\n",
    "print(\"\\nPredicted CSAT Score for new data:\", prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
